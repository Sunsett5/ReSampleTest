nohup: ignoring input
Device set to cuda:1.
Loading model from models/ldm/model.ckpt
/home/workspace/sun/ReSampleTest/model_loader.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  pl_sd = torch.load(ckpt)#, map_location="cpu")
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 274.06 M params.
Keeping EMAs of 370.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
making attention of type 'vanilla' with 512 in_channels
/home/workspace/sun/ReSampleTest/ldm/models/autoencoder.py:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  sd = torch.load(path, map_location="cpu")["state_dict"]
Restored from models/first_stage_models/vq-f4/model.ckpt with 0 missing and 55 unexpected keys
Training LatentDiffusion as an unconditional model.
Operation: inpainting / Noise: gaussian
Condition <ldm_inverse.condition_methods.PosteriorSampling object at 0x7001c09cef50>
Conditioning method <bound method PosteriorSampling.conditioning of <ldm_inverse.condition_methods.PosteriorSampling object at 0x7001c09cef50>>
Conditioning sampler : resample
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
Inference for image 0
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
/home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
/home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)
measurement psnr:  35.3852645744647
measurement nmse:  0.003461007960140705
measurement ssim:  0.9375262
measurement lpips:  0.11341336369514465
Inference for image 1
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
measurement psnr:  30.440938792772357
measurement nmse:  0.0031573690939694643
measurement ssim:  0.9095169
measurement lpips:  0.12291862070560455
Inference for image 2
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
measurement psnr:  23.531307688112285
measurement nmse:  0.01627541519701481
measurement ssim:  0.80506086
measurement lpips:  0.18849532306194305
Inference for image 3
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
measurement psnr:  33.076461910691066
measurement nmse:  0.0010975712211802602
measurement ssim:  0.95005465
measurement lpips:  0.11066274344921112
Inference for image 4
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
measurement psnr:  33.262577180527146
measurement nmse:  0.0023251890670508146
measurement ssim:  0.9291486
measurement lpips:  0.19288180768489838
Inference for image 5
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
measurement psnr:  31.861620559951675
measurement nmse:  0.003597915405407548
measurement ssim:  0.93107325
measurement lpips:  0.10503838956356049
Inference for image 6
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
measurement psnr:  31.48375337197935
measurement nmse:  0.002986534731462598
measurement ssim:  0.8896632
measurement lpips:  0.13946081697940826
Inference for image 7
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
measurement psnr:  33.321593962765434
measurement nmse:  0.00294301169924438
measurement ssim:  0.90921885
measurement lpips:  0.16493795812129974
Inference for image 8
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
measurement psnr:  31.41574978563966
measurement nmse:  0.0034063432831317186
measurement ssim:  0.86020833
measurement lpips:  0.19845841825008392
Inference for image 9
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /home/workspace/sun/ReSampleTest/ReSampleTest/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth
measurement psnr:  32.41588757358075
measurement nmse:  0.001107346499338746
measurement ssim:  0.9488471
measurement lpips:  0.0830584168434143
Inference for image 10
Data shape for DDIM sampling is (1, 3, 64, 64), eta 0.0
